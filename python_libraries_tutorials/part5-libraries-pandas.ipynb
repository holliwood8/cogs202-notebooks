{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4fe44d2",
   "metadata": {},
   "source": [
    "\n",
    "# pandas DataFrames\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9392fde",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "- How do I read in data from a file?\n",
    "- How can I work with data in tabular format (tables)?\n",
    "- How can I do basic descriptive statistics on tabular data?\n",
    "\n",
    "## Learning Objectives:\n",
    "- Select individual values from a Pandas dataframe\n",
    "- Select entire rows or entire columns from a dataframe\n",
    "- Select a subset of both rows and columns from a dataframe in a single operation\n",
    "- Select a subset of a dataframe by a single Boolean criterion\n",
    "- Obtain descriptive statistics for subsets of data within a table\n",
    "- Use the split-apply-combine paradigm to work with data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0b97d",
   "metadata": {},
   "source": [
    "## What is pandas?\n",
    "\n",
    "Bad news first: there are no cute, black-and-white bears here. [pandas](https://pandas.pydata.org/docs/) (whose official name starts with a lower-case \"p\") is a Python *library* for working with data in a tabular format, such as is found in file formats like CSV, Microsoft Excel, and Google Sheets. Unlike Excel or Sheets, pandas is not a point-and click graphical interface for working with these files — everything is done through Python code. But compared to other formats for working with data, such as lists and dictionaries, pandas may seem more familiar, and it definitely lends itself more naturally to large data sets. Indeed, pandas' mission statement is, \"...to be the fundamental high-level building block for doing practical, real world data analysis in Python\". \n",
    "\n",
    "The primary units of pandas data storage you will work with are [DataFrames](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/01_table_oriented.html#min-tut-01-tableoriented) (essentially, tables of data organized as rows and columns). DataFrames are actually collections of pandas [Series](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html) objects, which can be thought of as individual rows or columns (or vectors, or 1D arrays). \n",
    "\n",
    "Among the things that make pandas so attractive are the powerful interface to access individual records of the table, proper handling of missing values, and relational-databases operations between DataFrames. As well, pandas functions and methods are written to work intuitively and efficiently with data organized in tables. Most operations are *vectorized*, which means that they will automatically apply to all values in a DataFrame or Series without the need to write `for` loops to execute the same operation on a set of cells.\n",
    "\n",
    "pandas is built on top of the [NumPy](https://numpy.org) library. It's worth noting for your future reference that most of the methods defined for NumPy Arrays also apply to Pandas Series/DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28364a5f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "~~~python\n",
    "import pandas\n",
    "~~~\n",
    "\n",
    "Once a library is imported, we can use functions and methods from it. But, for functions we have to tell Python that the function can be found in a particular library we imported. For example, pandas has a function to import data from CSV (comma-separated value) files, called `read_csv`. To run this command, we would need to type:\n",
    "\n",
    "~~~python\n",
    "pandas.read_csv()\n",
    "~~~\n",
    "\n",
    "Since some package names are long, and adding the name to every function can result in a lot of typing, Python also allows us to assign an *alias* — a shorter name — to a library when we import it. For example, the convention for pandas is to give it the alias `pd` like this:\n",
    "\n",
    "~~~python\n",
    "import pandas as pd\n",
    "~~~\n",
    "\n",
    "Then to read a CSV file we could use:\n",
    "\n",
    "~~~python\n",
    "pd.read_csv()\n",
    "~~~\n",
    "\n",
    "In the cell below, import pandas with the alias pd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15175736-ed4e-4aa8-b511-714e35d2fa02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa80c3f0-ac11-44ff-8f5e-55a0ef071b8a",
   "metadata": {},
   "source": [
    "## Dataframes and Series\n",
    "\n",
    "The main type of data structure in `pandas` is a `DataFrame`, which\n",
    "organizes data into a 2D table, like a spreadsheet. Unlike a `numpy`\n",
    "array, however, each column in a `DataFrame` can have different data\n",
    "types - for example, you can have a string column, an integer column,\n",
    "and a float column all in the same `DataFrame`.\n",
    "\n",
    "(The other major type of data in `pandas` is a `Series`, which is like a\n",
    "1D array- any individual row or column from a `DataFrame` will be a\n",
    "`Series`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163fa131-01bd-43cd-b5f4-a9afd7bba20e",
   "metadata": {},
   "source": [
    "You *can* create a `DataFrame` or a `Series` “by hand” - for example,\n",
    "try\n",
    "\n",
    "``` python\n",
    "pd.Series([1,2,3,99])\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "``` python\n",
    "pd.DataFrame({'fruit': ['apple', 'banana', 'kiwi'], 'cost': [0.55, 0.99, 1.24]})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92b825-2972-4cc1-8f64-aa4106c35a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "432fc30e",
   "metadata": {},
   "source": [
    "## Importing data with pandas\n",
    "\n",
    "As noted, we can read a CSV file and use it to create a pandas DataFrame, with the funciton `pd.read_csv()`. [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) is a text format used for storing tabular data, in which each line of the file corresponds to a row in the table, and columns are separated with commas (\"CSV\" stands for \"comma-separated values\"). Often the first row of a CSV file will be the *header*, containing labels for each column. \n",
    "\n",
    "The ADNI data subset is in CSV format, so let's load in the data with the command below. This data was collected as part of the Alzheimer’s Disease Neuroimaging Initiative (ADNI). ADNI researchers collected a wide variety of measurements including MRI and PET images, genetics, cognitive tests, CSF and blood biomarkers as predictors of the disease (See more information here: https://adni.loni.usc.edu/)\n",
    "\n",
    "Note that when we read in a DataFrame, we need to assign it to a variable name so that we can reference it later. A convention when working with pandas is to call the DataFrame `df`. This works fine if you only have one DataFrame to work with, although if you are working with multiple DataFrames it is a good idea to give them more meaningful names.\n",
    "\n",
    "The data are stored in a subfolder called `data`, so as the argument to `pd.read_csv()` below we give the folder name folled by a slash, then the file name:\n",
    "\n",
    "~~~python\n",
    "df = pd.read_csv('data/TADPOLE_select.csv')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3113e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "526f1678",
   "metadata": {},
   "source": [
    "We can view the contents of the DataFrame `df` by simply typing its name and running the cell. Note that, unlike most of the examples we've used in previous lessons, we *don't* use the `print()` function. Although it works, the result is not nicely formatted the way the output is if we just use the name of the data frame.\n",
    "\n",
    "That is, run this command: `df` — not `print(df)` — in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee896a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "345a2637",
   "metadata": {},
   "source": [
    "You'll see that the rows are numbered in boldface, starting with 0 as is the norm in Python. This boldfaced, leftmost column is called the **index** of the DataFrame, and provides one way of accessing data by rows. Across the top, you'll see that the column labels are also in boldface. pandas is pretty smart about automatically detecting when the first row of a CSV file contains header information (column names)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1027970a-ce0b-45a6-931e-2a87a88d4561",
   "metadata": {},
   "source": [
    "You can access the column names in the data using the `columns` attribute of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d77ac2-4249-478d-b375-30ae080f4727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e911e64-7ecb-4a68-9fda-828ea94ac649",
   "metadata": {},
   "source": [
    "Dataframe have lots of other useful attributes as well like `index`, `dtypes`, `size`, `shape`, `ndim`\n",
    "\n",
    "The `index` index attribute is used to display the row labels of a data frame object. The row labels can be of 0,1,2,3,… form and can be of names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f7356-e446-43fa-9337-ad6951543554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05653dda-0696-4fce-9117-90beb54d67a5",
   "metadata": {},
   "source": [
    "We can also get a quick summary with info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103cc04d-7b69-4c16-878a-6003f0ed581a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e5a7bcc-5586-4622-9a34-643c08f0a00d",
   "metadata": {},
   "source": [
    "`read_csv` is for “flat” text files, where each data point is on another\n",
    "row, and the fields in a row are separated by some delimiter\n",
    "(e.g. comma). Other pandas functions exist for loading other kinds of\n",
    "data (read from database, Excel file, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1071ecf1",
   "metadata": {},
   "source": [
    "## Heads or Tails?\n",
    "\n",
    "We might want to \"peek\" at the DataFrame without printing out the entire thing, especially if it's big. We can see the first 5 rows of a DataFrame with the `.head()` method:\n",
    "\n",
    "~~~python\n",
    "df.head()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe365c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f7e6edf",
   "metadata": {},
   "source": [
    "...or the last 5 rows with `.tail()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b4fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a224865",
   "metadata": {},
   "source": [
    "We can also see a random sample of rows from the DataFrame with `.sample()`, giving it a numerical argument to indicate the number of rows we want to see:\n",
    "\n",
    "~~~python\n",
    "df.sample(10)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec232369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d7811b3",
   "metadata": {},
   "source": [
    "Note that the `.head()` and `.tail()` methods also optionally take a numerical argument, if you want to view a different number of rows from the default of 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4675e6bc-5667-4305-aa33-fb32c8533cd2",
   "metadata": {},
   "source": [
    "Looking at some rows can help us spot obvious problems with data loading. For example, suppose we had tried to read in the data using a tab delimiter to separate fields on the same row, instead of a comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab5bd9-6013-4671-86d6-64cc19dcd2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c1fa372-a6e3-4f11-9306-b6dd7e55cf35",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e56bee7c-6c17-4e82-83ae-e3d87928640c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Accessing values in a DataFrame\n",
    "\n",
    "One thing we often want to do is access a single cell in a DataFrame, or a range of cells. Each cell is uniquely defined by a combination of its row and column locations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2853b936-2d36-4f90-9e65-b9f85177a1a8",
   "metadata": {},
   "source": [
    "### Select a column using `[]`\n",
    "\n",
    "If we want to select an entire column of a pandas DataFrame, we just give the name of the DataFrame followed by the column name in square brackets. Below we are selecting the 'DX' (diagnosis) column\n",
    "\n",
    "~~~python\n",
    "df['DX']\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156ffa8-6616-4403-846c-a608c8b87ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2ea75f6-4806-47e0-a1fe-f0ad4c4e0770",
   "metadata": {},
   "source": [
    "Note that if we ask for a single column the result is a pandas Series, but if we ask for two or more columns, the result is a DataFrame. Pay close attention to the syntax below — if we're asking for more than one column, we need to provide a *list* of columns inside the square brackets (so there are *two* sets of nested square brackets in the code below):\n",
    "\n",
    "~~~python\n",
    "df[['DX', 'AGE']]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9666ba69-1d3b-43cf-8f51-85939fa30215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "552b122b-de4a-4331-a31f-ae218213645a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Numerical indexing using `.iloc[]`\n",
    "\n",
    "Often we don't want to access an entire column, however, but just specific rows within a column (or range of columns). pandas provides two ways of accessing cell locations. One is using the numerical positions in the DataFrame, using the convention of [row, column] — with [0, 0] being the top left cell in the DataFrame. So for a pandas DataFrame with 3 rows and 3 columns, the indices of each cell are as shown:\n",
    "\n",
    "|   | col 0  | col 1  | col 2  | col 3  |\n",
    "|---|--------|--------|--------|--------|\n",
    "| 0 | [0, 0] | [0, 1] | [0, 2] | [0, 3] |\n",
    "| 1 | [1, 0] | [1, 1] | [1, 2] | [1, 3] |\n",
    "| 2 | [2, 0] | [2, 1] | [2, 2] | [2, 3] |\n",
    "| 3 | [3, 0] | [3, 1] | [3, 2] | [3, 3] |\n",
    "\n",
    "\n",
    "Numerical indexing of DataFrames is done with the `.iloc[]` method. For example, to access the DX value for patient # 4  — which is located in the fifth row, third column of our current DataFrame, we would use:\n",
    "\n",
    "~~~python\n",
    "df.iloc[4, 2]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de0e6a-1318-4b85-a5aa-6400fc87d527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdfa7f4c",
   "metadata": {},
   "source": [
    "## Label-based indexing using `.loc[]`\n",
    "\n",
    "The other way to access a location in a DataFrame is by its index and column *labels*, using the `.loc[]` method. As noted earlier, in the DataFrame we imported, the indexes are currently numbers, which were created automatically when we imported the data. The `.loc[]` method doesn't work with numerical indexes (that's what `iloc` is for — and you can't mix, say, a numerical row index with a column label), but in the data set we imported, the first column of this CSV file is actually meant to be its index: while all other columns are data values (DX, AGE, APOE4 etc.), the first column identifies the patient with which each row of data is associated. \n",
    "\n",
    "pandas has a method for setting an index column, `.set_index()`, where the argument (in the parentheses) would be the name of the column to use as the index. So here we want to run:\n",
    "\n",
    "~~~python\n",
    "df = df.set_index('PTID_Key')\n",
    "~~~\n",
    "\n",
    "**Note** that we need to assign the result of this operation back to `df` (using `df = `), otherwise the change will not actually modify `df`.\n",
    "\n",
    "In the cell below, use the `.set_index()` method to set the index of `df` to `PTID_Key`, and then view the DataFrame again to see how it has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4469e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7746fbd",
   "metadata": {},
   "source": [
    "Alternatively, if we knew which column we wanted to use as the index before loading in the data file, we could have included the argument `index_col=` in the `pd.read_csv()` command:\n",
    "\n",
    "~~~python\n",
    "df = pd.read_csv('data/TADPOLE_select.csv', index_col='PTID_Key')\n",
    "~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8998a85d-c296-47d9-90a5-e2bad3a25ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db963af7",
   "metadata": {},
   "source": [
    "Now that we have defined the index, we can access the cognitive score (say MMSE) value for patient with ID # 347 by its index and column names:\n",
    "\n",
    "~~~python\n",
    "df.loc[347, 'MMSE']\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e1ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "347d116b",
   "metadata": {},
   "source": [
    "## Use `:` on its own to mean all columns or all rows.\n",
    "\n",
    "Using Python's familiar slicing notation (which we've previously used for strings and lists), we can use `:` with `.iloc[]` or `.loc[]`, to specify a range in a DataFrame.\n",
    "\n",
    "For example, to see the data of patient with ID# 400 for every variable (column) in the DataFrame, we would use:\n",
    "\n",
    "~~~python\n",
    "df.loc[400, :]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003a1e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d7e7e6d",
   "metadata": {},
   "source": [
    "Likewise, we could see the MMSE scores for every patient with:\n",
    "\n",
    "~~~python\n",
    "df.loc[:, 'MMSE']\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe26e6-9b81-47b2-8dd3-857f5b9c289e",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7f8b81a",
   "metadata": {},
   "source": [
    "You can also just specify the row index; if you don't specify anything for the columns, pandas assumes you want all columns:\n",
    "\n",
    "~~~python\n",
    "df.loc[400]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f566a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78f636c3",
   "metadata": {},
   "source": [
    "However, since the syntax for `.iloc[]` and `.loc[]` is [rows, columns], you cannot omit a row index; you need to use `:` if you want all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7017f-d3ad-4e1a-a501-996207870eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a871efab",
   "metadata": {},
   "source": [
    "## Slicing works on DataFrames\n",
    "\n",
    "Slicing using numerical indices works similarly for DataFrames as we previously saw for strings and lists, for example, the following code will print the third through fifth rows of the DataFrame, and the fifth through eighth columns (remember, Python indexing starts at 0, and slicing does not include the \"end\" index): \n",
    "\n",
    "~~~python\n",
    "df.iloc[2:5, 4:8]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25b611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "488e8bad",
   "metadata": {},
   "source": [
    "The code below will print from the sixth to second-last row of the DataFrame, and from the ninth to the last column:\n",
    "\n",
    "~~~python\n",
    "df.iloc[5:-1, 8:]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a0a875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21fc0282",
   "metadata": {},
   "source": [
    "**Note** however, that when using label-based indexing with `.loc[]`, pandas' slicing behaviour is a bit different. Specifically, the output *includes* the last item in the range, whereas numerical indexing with `.iloc[]` does not. \n",
    "\n",
    "So, considering that the first three rows of the DataFrame correspond to the patient IDs 400, 564 and 1354 and that columns 8 through 11 are the volumes for hippocampus, wholebrain, entorhinal cortex and fusiform regions, compare the output of:\n",
    "\n",
    "~~~python\n",
    "df.iloc[0:2, 8:11]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0feec2-24bd-4719-87ad-caa1c0316ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7053eebe",
   "metadata": {},
   "source": [
    "with:\n",
    "\n",
    "~~~python\n",
    "df.loc[400:1354, 'Hippocampus': 'Fusiform']\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710c6adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "189f599d",
   "metadata": {},
   "source": [
    "The \"inclusive\" label-based indexing with `.loc[]` is fairly intuitive, but it's important to remember that it works differently from numerical indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0736538",
   "metadata": {},
   "source": [
    "## Use lists to select non-contiguous sections of a DataFrame\n",
    "\n",
    "While slicing can be very useful, sometimes we might want to extract values that aren't next to each other in a DataFrame. For example, what if we only want values for the MMSE scores and diagnosis (DX), for patients with IDs (398, 613, 522)? Neither these patient IDs nor variables are in adjacent columns/rows in the DataFrame. With `.loc[]`, we can use lists, rather than ranges separated by `:`, as selectors:\n",
    "\n",
    "~~~python\n",
    "df.loc[[398, 613, 522], ['DX', 'MMSE']]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfafc9fc-93ec-456c-a17e-c8959454a0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9d389a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfe33529",
   "metadata": {},
   "source": [
    "We can equivalently write the command over several lines to make it a bit easier to read:\n",
    "\n",
    "~~~python\n",
    "df.loc[[398, 613, 522], \n",
    "        ['DX', 'MMSE']]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbfa659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1562c15b",
   "metadata": {},
   "source": [
    "We could also define those lists as variables, and pass the variables to `.loc[]`. This might be useful if you were going to use the lists more than once, as well as for clarity:\n",
    "\n",
    "~~~python\n",
    "patient_IDs = [398, 613, 522]\n",
    "variables = ['DX', 'MMSE']\n",
    "df.loc[patient_IDs, variables]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03fd757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab187c19",
   "metadata": {},
   "source": [
    "We can take this a step further, and assign the output of a `.loc[]` selection like this to a new variable name. This makes a copy of the selected data, stored in a new DataFrame (or Series, if we only select one row or column) with its own name. This allows us to later reference and use that selection. \n",
    "\n",
    "~~~python\n",
    "subset_data = df.loc[patient_IDs, variables]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d019938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "010f0c70-2676-47a0-bc3b-68acd4ae7fc5",
   "metadata": {},
   "source": [
    "Selecting non-contiguous sections with numerical indexing\n",
    "Try the following\n",
    "```python \n",
    "df.iloc[[0,2], [1,-2]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f72ee79",
   "metadata": {},
   "source": [
    "## It's easy to do simple math and statistics in DataFrames\n",
    "\n",
    "We prevoiusly learned about methods to get simple statistical values out of a Python list, like `.max()`, and `.min()`. pandas includes these and many more methods as well. For example, we can view the mean volume of the Hippocampus across all patients (rows) with:\n",
    "\n",
    "~~~python\n",
    "df.loc[:, 'Hippocampus'].mean()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79bcc64",
   "metadata": {},
   "source": [
    "Or max along a row, say for patient ID 400\n",
    "\n",
    "~~~python\n",
    "df.loc[400].max()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5480d7-ef8c-4e5a-9be7-c2d2f620afca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2379e349-dadc-4fa7-8e02-8835ffab9832",
   "metadata": {},
   "source": [
    "The above doesn't work since some columns are not of numeric type. We can first extract columns with data type numeric (say float) and then compute the max in this case\n",
    "```python\n",
    "df.loc[400, df.columns[df.dtypes == 'float64']].max()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0730ae1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de0ac82b",
   "metadata": {},
   "source": [
    "Another useful method is `.describe()`, which prints out a range of descriptive statistics for the range of data you specify. Without any slicing it provides information for each column:\n",
    "\n",
    "~~~python\n",
    "df.describe()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4a7c7d9b-703f-4d10-89ec-f235d830923e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>Hippocampus</th>\n",
       "      <th>WholeBrain</th>\n",
       "      <th>Entorhinal</th>\n",
       "      <th>Fusiform</th>\n",
       "      <th>MidTemp</th>\n",
       "      <th>ICV</th>\n",
       "      <th>ADAS13</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>Ventricles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1669.000000</td>\n",
       "      <td>1669.000000</td>\n",
       "      <td>1667.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1.332000e+03</td>\n",
       "      <td>1091.000000</td>\n",
       "      <td>1091.000000</td>\n",
       "      <td>1091.000000</td>\n",
       "      <td>1.360000e+03</td>\n",
       "      <td>1434.000000</td>\n",
       "      <td>1437.000000</td>\n",
       "      <td>1324.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73.791791</td>\n",
       "      <td>15.937088</td>\n",
       "      <td>0.561488</td>\n",
       "      <td>6817.128609</td>\n",
       "      <td>1.025091e+06</td>\n",
       "      <td>3529.007333</td>\n",
       "      <td>17729.987168</td>\n",
       "      <td>19695.106324</td>\n",
       "      <td>1.523213e+06</td>\n",
       "      <td>17.575767</td>\n",
       "      <td>26.899095</td>\n",
       "      <td>40817.602719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.196902</td>\n",
       "      <td>2.831223</td>\n",
       "      <td>0.660335</td>\n",
       "      <td>1215.890371</td>\n",
       "      <td>1.114866e+05</td>\n",
       "      <td>786.346886</td>\n",
       "      <td>2781.797029</td>\n",
       "      <td>3041.776697</td>\n",
       "      <td>1.668303e+05</td>\n",
       "      <td>10.524535</td>\n",
       "      <td>3.147530</td>\n",
       "      <td>22918.334187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2991.000000</td>\n",
       "      <td>6.693640e+05</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>10012.000000</td>\n",
       "      <td>9375.000000</td>\n",
       "      <td>7.089130e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5650.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>69.200000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5963.000000</td>\n",
       "      <td>9.477940e+05</td>\n",
       "      <td>3025.000000</td>\n",
       "      <td>15958.500000</td>\n",
       "      <td>17736.000000</td>\n",
       "      <td>1.404960e+06</td>\n",
       "      <td>9.330000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>23611.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>73.900000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6929.000000</td>\n",
       "      <td>1.021660e+06</td>\n",
       "      <td>3563.000000</td>\n",
       "      <td>17633.000000</td>\n",
       "      <td>19675.000000</td>\n",
       "      <td>1.513275e+06</td>\n",
       "      <td>15.165000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>35650.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7664.500000</td>\n",
       "      <td>1.098638e+06</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>19552.500000</td>\n",
       "      <td>21813.000000</td>\n",
       "      <td>1.624448e+06</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>52629.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>91.400000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10699.000000</td>\n",
       "      <td>1.486040e+06</td>\n",
       "      <td>5896.000000</td>\n",
       "      <td>29950.000000</td>\n",
       "      <td>32189.000000</td>\n",
       "      <td>2.110290e+06</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>156066.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AGE     PTEDUCAT        APOE4   Hippocampus    WholeBrain  \\\n",
       "count  1669.000000  1669.000000  1667.000000   1143.000000  1.332000e+03   \n",
       "mean     73.791791    15.937088     0.561488   6817.128609  1.025091e+06   \n",
       "std       7.196902     2.831223     0.660335   1215.890371  1.114866e+05   \n",
       "min      55.000000     4.000000     0.000000   2991.000000  6.693640e+05   \n",
       "25%      69.200000    14.000000     0.000000   5963.000000  9.477940e+05   \n",
       "50%      73.900000    16.000000     0.000000   6929.000000  1.021660e+06   \n",
       "75%      79.000000    18.000000     1.000000   7664.500000  1.098638e+06   \n",
       "max      91.400000    20.000000     2.000000  10699.000000  1.486040e+06   \n",
       "\n",
       "        Entorhinal      Fusiform       MidTemp           ICV       ADAS13  \\\n",
       "count  1091.000000   1091.000000   1091.000000  1.360000e+03  1434.000000   \n",
       "mean   3529.007333  17729.987168  19695.106324  1.523213e+06    17.575767   \n",
       "std     786.346886   2781.797029   3041.776697  1.668303e+05    10.524535   \n",
       "min    1143.000000  10012.000000   9375.000000  7.089130e+05     0.000000   \n",
       "25%    3025.000000  15958.500000  17736.000000  1.404960e+06     9.330000   \n",
       "50%    3563.000000  17633.000000  19675.000000  1.513275e+06    15.165000   \n",
       "75%    4066.000000  19552.500000  21813.000000  1.624448e+06    24.000000   \n",
       "max    5896.000000  29950.000000  32189.000000  2.110290e+06    71.000000   \n",
       "\n",
       "              MMSE     Ventricles  \n",
       "count  1437.000000    1324.000000  \n",
       "mean     26.899095   40817.602719  \n",
       "std       3.147530   22918.334187  \n",
       "min       7.000000    5650.000000  \n",
       "25%      25.000000   23611.500000  \n",
       "50%      28.000000   35650.500000  \n",
       "75%      29.000000   52629.750000  \n",
       "max      30.000000  156066.000000  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb59c34-4254-4dd5-b116-655c85832586",
   "metadata": {},
   "source": [
    "For categorical variables, you can compute the mode or check the unique values using the .mode() and .unique() methods\n",
    "e.g. \n",
    "```python\n",
    "df.loc[:,'PTETHCAT'].unique()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c8a195-6f37-4275-9d31-5262a8a0c29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c680de2c",
   "metadata": {},
   "source": [
    "### Mini-Exercise\n",
    "In the cell below, try to view descriptive statistics for columns [MMSE, Ventricles, ADAS13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3391b3-32dd-493d-8b94-cdc54271746e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a3fb6d5",
   "metadata": {},
   "source": [
    "## Evaluate cells based on conditions\n",
    "\n",
    "pandas allows an easy way to identify values in a DataFrame that meet a certain condition, using operators like `<`, `>`, and `==`. For example, let's see which patients in a list had a diagnosis of AD. The result is reported in Booleans (True/False) for each cell.\n",
    "\n",
    "~~~python\n",
    "patients = [1511, 583, 284, 1007, 316, 1124, 1558, 1367, 823, 235]\n",
    "df.loc[patients, 'DX']  == 'Dementia'\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed632256-19ca-452b-96f2-fa203e5ef784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4a88d80-a733-4a4b-89d3-bc76db3899bd",
   "metadata": {},
   "source": [
    "Evaluate all rows using the `:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78bf674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fa9a2f1-2f1c-4f85-a353-ba0d1f1ffa05",
   "metadata": {},
   "source": [
    "compare with \n",
    "```python \n",
    "    df['DX'] == 'Dementia'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a956e2-99d8-4354-a73e-10e0e0c99781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7234d2db-d10c-4483-a260-d827d40fb8f6",
   "metadata": {},
   "source": [
    "Try the same for numeric variables: \n",
    "```python \n",
    " df.loc[patients, 'AGE'] < 80           \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54055ef5-0aa3-4747-9175-1579a202cfa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65984688",
   "metadata": {},
   "source": [
    "## Select values or NaN using a Boolean mask.\n",
    "\n",
    "A DataFrame full of Booleans is sometimes called a *mask* because of how it can be used. A mask removes values that are not True, and replaces them with `NaN` — a special Python value representing \"not a number\". This can be useful because pandas ignores NaN values when doing computations. \n",
    "\n",
    "We create a mask by assigning the output of a conditional statement to a variable name:\n",
    "\n",
    "\n",
    "~~~python\n",
    "mask = df.loc[:, 'DX'] == 'Dementia'\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c65613-5058-49a1-ba7d-026fd8b9ee99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4edef08f",
   "metadata": {},
   "source": [
    "Then we can apply the mask to the DataFrame to get only the values that meet the criterion:\n",
    "\n",
    "~~~python\n",
    "df[mask]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de222c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "423f481c-8fee-4a8f-8b14-2a1b80068af3",
   "metadata": {},
   "source": [
    "You can also combine different conditions \n",
    "```python\n",
    "mask = (df.loc[:, 'AGE'] < 80) & (df.loc[:, 'PTGENDER'] == 'Male')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0393520-56b2-49ee-ae28-9071a75922cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2326b407",
   "metadata": {},
   "source": [
    "As an example of how this might be used, the steps above would now allow us to find the mean age of patients with Dementia:\n",
    "\n",
    "~~~python\n",
    "mask = df.loc[:, 'DX'] == 'Dementia'\n",
    "df_dementia = df[mask]\n",
    "df_dementia.loc[:,'AGE'].mean()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb5f12-0d64-4eef-a9e4-ef9bb9bb0d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f83fbb33-e737-45bc-8fd3-702ba473d703",
   "metadata": {},
   "source": [
    "### Mini-Exercise\n",
    "Research has shown that the APOE4 gene can increase the risk of developing Alzheimer's disease. Compute the most frequent value of the APOE4 gene\n",
    "factor among patients who are cognitively normal (DX: 'NL') and patients who have dementia\n",
    "\n",
    "Hint: You can use the .mode() method and boolean masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c0d8fb-efa7-46a2-93e5-0556346a52f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a3c4933-7934-4ab4-bcc2-73796e1e033f",
   "metadata": {},
   "source": [
    "Now, compute and compare the mean MMSE scores for patients with dementia and cognitively normal patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b05a2-a2f7-4793-b751-4c2e481f057b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71411f82-3b60-4400-9675-9723dbbbdb43",
   "metadata": {},
   "source": [
    "What about the hippocampal volumes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927103c-628e-458d-9df3-83dfcd9fcb28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57bb0ddc",
   "metadata": {},
   "source": [
    "## Split-Apply-Combine\n",
    "\n",
    "A common task in data science is to split data into meaningful subgroups, apply an operation to each subgroup (e.g., compute the mean), and then combine the results into a single output, such as a table or a new DataFrame. This paradigm was famously [described by Hadley Wickham in a 2011 paper](http://dx.doi.org/10.18637/jss.v040.i01).\n",
    "\n",
    "pandas provides methods and grouping operations that are very efficient (*vectorized*) for split-apply-combine operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9eca1",
   "metadata": {},
   "source": [
    "As an example, let's say that we wanted to compare the average hippocampal volumes and MMSE scores for different groups of patients. To do this, we first have to create lists defining the patients belonging to each of these groups. In the following, we just create these groups randomly. \n",
    "\n",
    "~~~python\n",
    "import random\n",
    "group1 = random.sample(list(df.index.values), 10)\n",
    "group2 = random.sample(list(df.index.values), 10)\n",
    "group3 = random.sample(list(df.index.values), 10)\n",
    "group4 = random.sample(list(df.index.values), 10)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c404372f-3bd2-4dbd-b106-a75f02f3295a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdc15c40",
   "metadata": {},
   "source": [
    "Next we can make a new column simply by using `.loc[]` with the rows specified by one of the lists we just defined, a column name that doesn't already exist (in this case, we'll call it \"group_id\"), then assigning a group label to that combination of rows and column. We need to do this separately for each group. Note that when we first create the new column (\"group\"), pandas fills it with NaN values in any rows that were not defined by the assignment. For example, in the code below, the first line will create the column \"group\", and fill it with \"1\" for any row in the `group1` list, and `NaN` to every other row. \n",
    "\n",
    "~~~python\n",
    "df.loc[group1, 'group_id'] = '1'\n",
    "df.loc[group2, 'group_id'] = '2'\n",
    "df.loc[group3, 'group_id'] = '3'\n",
    "df.loc[group4, 'group_id'] = '4'\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda31af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69b9bc1a",
   "metadata": {},
   "source": [
    "### Split\n",
    "\n",
    "Now we can use this \"region\" column to split the data into groups, using a pandas method called `.groupby()`\n",
    "\n",
    "~~~python\n",
    "grouped_patients = df.groupby('group_id')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b1928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9957fb96",
   "metadata": {},
   "source": [
    "Note that this step doesn't create a new DataFrame, it creates a special kind of pandas object that points to a grouping in the original DataFrame:\n",
    "\n",
    "~~~python\n",
    "type(grouped_patients)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae12267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc236315",
   "metadata": {},
   "source": [
    "### Apply\n",
    "\n",
    "Now that we have split the data, we can apply a function separately to each group. Here we'll compute the mean hippocampal volumes and MMSE scores for each group:\n",
    "\n",
    "~~~python\n",
    "means_by_group = grouped_patients[['Hippocampus', 'MMSE']].mean()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9150b7e-7480-486e-ac74-75731b945781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cffddcaf",
   "metadata": {},
   "source": [
    "### Combine\n",
    "\n",
    "The combine step actually occurred with the *apply* step above — the result is automatically combined into a table of mean values organized by region. But since our *apply* step (`.mean()`) saved the result to a variable, we can view the resulting table as the output of the *combine* step:\n",
    "\n",
    "~~~python\n",
    "means_by_group\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e797211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93a5f0ea",
   "metadata": {},
   "source": [
    "### Chaining\n",
    "\n",
    "In Python, **chaining** refers to combining a number of operations in one command, using a sequence of methods. We can perform the above split-apply-combine procedure in a single step as follows. Note that because we don't assign the output to a variable name, it is displayed as output but not saved.\n",
    "\n",
    "~~~python\n",
    "df.groupby('group_id')[['Hippocampus', 'MMSE']].mean()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443aa9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ea3bc09-51e8-4388-b224-18fd8b64a55e",
   "metadata": {},
   "source": [
    "You can group data based on existing column names too <br>\n",
    "```python\n",
    "df.groupby('DX')['Hippocampus'].mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de12e6a-6594-4fcc-9d74-3acbc813125f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d076a71b-e76e-49ff-8e5d-3af58190db9c",
   "metadata": {},
   "source": [
    "compare with \n",
    "```python\n",
    "df.loc[:,['DX', 'Hippocampus']].groupby('DX').mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe439354-196e-4dbe-a2e9-ec22a94d400f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76bced0d",
   "metadata": {},
   "source": [
    "---\n",
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7602c69",
   "metadata": {},
   "source": [
    "## Selecting Individual Values\n",
    "\n",
    "Write an expression to find the MMSE score of patient ID # 635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a746f-40d1-475f-b851-dfb3899e9b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbf2ffc9",
   "metadata": {},
   "source": [
    "#### Extent of Slicing\n",
    "\n",
    "1.  Do the two statements below produce the same output? (Hint: you might want to use the `.head()` method to remind yourself of the structure of the DataFrame)\n",
    "2.  Based on this, what rule governs what is included (or not) in numerical slices and named slices in Pandas?\n",
    "\n",
    "~~~python\n",
    "print(df.iloc[0:2, 0:2])\n",
    "print(df.loc[400:1354, 'EXAMDATE':'AGE'])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "7a6ab979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXAMDATE</th>\n",
       "      <th>DX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>PTETHCAT</th>\n",
       "      <th>PTMARRY</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>Hippocampus</th>\n",
       "      <th>WholeBrain</th>\n",
       "      <th>Entorhinal</th>\n",
       "      <th>Fusiform</th>\n",
       "      <th>MidTemp</th>\n",
       "      <th>ICV</th>\n",
       "      <th>ADAS13</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>Ventricles</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTID_Key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>9/8/05</td>\n",
       "      <td>NL</td>\n",
       "      <td>74.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>16</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8336.0</td>\n",
       "      <td>1229740.0</td>\n",
       "      <td>4177.0</td>\n",
       "      <td>16559.0</td>\n",
       "      <td>27936.0</td>\n",
       "      <td>1984660.0</td>\n",
       "      <td>18.67</td>\n",
       "      <td>28.0</td>\n",
       "      <td>118233.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>9/12/05</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>81.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5319.0</td>\n",
       "      <td>1129830.0</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>15506.0</td>\n",
       "      <td>18422.0</td>\n",
       "      <td>1920690.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>84599.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>4/19/07</td>\n",
       "      <td>MCI</td>\n",
       "      <td>70.6</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7420.0</td>\n",
       "      <td>1060910.0</td>\n",
       "      <td>4169.0</td>\n",
       "      <td>19522.0</td>\n",
       "      <td>22864.0</td>\n",
       "      <td>1627060.0</td>\n",
       "      <td>16.67</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54752.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>3/26/07</td>\n",
       "      <td>MCI</td>\n",
       "      <td>69.7</td>\n",
       "      <td>Female</td>\n",
       "      <td>12</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6688.0</td>\n",
       "      <td>949914.0</td>\n",
       "      <td>3817.0</td>\n",
       "      <td>13838.0</td>\n",
       "      <td>17121.0</td>\n",
       "      <td>1396120.0</td>\n",
       "      <td>27.33</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16683.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>4/16/07</td>\n",
       "      <td>MCI</td>\n",
       "      <td>73.6</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>Hisp/Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5920.0</td>\n",
       "      <td>856238.0</td>\n",
       "      <td>3443.0</td>\n",
       "      <td>12897.0</td>\n",
       "      <td>12787.0</td>\n",
       "      <td>1398620.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27088.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>12/18/13</td>\n",
       "      <td>NL</td>\n",
       "      <td>69.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>14</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10602.0</td>\n",
       "      <td>1486040.0</td>\n",
       "      <td>4701.0</td>\n",
       "      <td>24783.0</td>\n",
       "      <td>32189.0</td>\n",
       "      <td>1998250.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18633.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>8/15/07</td>\n",
       "      <td>MCI</td>\n",
       "      <td>74.4</td>\n",
       "      <td>Male</td>\n",
       "      <td>14</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>3/5/09</td>\n",
       "      <td>MCI</td>\n",
       "      <td>82.8</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.67</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>10/25/11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.1</td>\n",
       "      <td>Female</td>\n",
       "      <td>18</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6254.0</td>\n",
       "      <td>954172.0</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>13415.0</td>\n",
       "      <td>18947.0</td>\n",
       "      <td>1415770.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>50196.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>6/11/12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>12</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1678780.0</td>\n",
       "      <td>41.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1669 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          EXAMDATE        DX   AGE PTGENDER  PTEDUCAT         PTETHCAT  \\\n",
       "PTID_Key                                                                 \n",
       "400         9/8/05        NL  74.3     Male        16  Not Hisp/Latino   \n",
       "564        9/12/05  Dementia  81.3     Male        18  Not Hisp/Latino   \n",
       "1354       4/19/07       MCI  70.6     Male        18  Not Hisp/Latino   \n",
       "221        3/26/07       MCI  69.7   Female        12  Not Hisp/Latino   \n",
       "518        4/16/07       MCI  73.6     Male         4      Hisp/Latino   \n",
       "...            ...       ...   ...      ...       ...              ...   \n",
       "882       12/18/13        NL  69.3     Male        14  Not Hisp/Latino   \n",
       "250        8/15/07       MCI  74.4     Male        14  Not Hisp/Latino   \n",
       "1507        3/5/09       MCI  82.8   Female        20  Not Hisp/Latino   \n",
       "347       10/25/11       NaN  74.1   Female        18  Not Hisp/Latino   \n",
       "820        6/11/12       NaN  88.3     Male        12  Not Hisp/Latino   \n",
       "\n",
       "           PTMARRY  APOE4  Hippocampus  WholeBrain  Entorhinal  Fusiform  \\\n",
       "PTID_Key                                                                   \n",
       "400        Married    0.0       8336.0   1229740.0      4177.0   16559.0   \n",
       "564        Married    1.0       5319.0   1129830.0      1791.0   15506.0   \n",
       "1354       Married    1.0       7420.0   1060910.0      4169.0   19522.0   \n",
       "221        Widowed    1.0       6688.0    949914.0      3817.0   13838.0   \n",
       "518        Married    0.0       5920.0    856238.0      3443.0   12897.0   \n",
       "...            ...    ...          ...         ...         ...       ...   \n",
       "882        Married    0.0      10602.0   1486040.0      4701.0   24783.0   \n",
       "250        Married    1.0          NaN         NaN         NaN       NaN   \n",
       "1507       Married    0.0          NaN         NaN         NaN       NaN   \n",
       "347       Divorced    0.0       6254.0    954172.0      2190.0   13415.0   \n",
       "820        Married    NaN       6480.0         NaN         NaN       NaN   \n",
       "\n",
       "          MidTemp        ICV  ADAS13  MMSE  Ventricles group_id  \n",
       "PTID_Key                                                         \n",
       "400       27936.0  1984660.0   18.67  28.0    118233.0        n  \n",
       "564       18422.0  1920690.0   31.00  20.0     84599.0        n  \n",
       "1354      22864.0  1627060.0   16.67  30.0     54752.0        n  \n",
       "221       17121.0  1396120.0   27.33  24.0     16683.0        1  \n",
       "518       12787.0  1398620.0   32.00  26.0     27088.0        n  \n",
       "...           ...        ...     ...   ...         ...      ...  \n",
       "882       32189.0  1998250.0   14.00  29.0     18633.0        n  \n",
       "250           NaN        NaN     NaN   NaN         NaN        n  \n",
       "1507          NaN        NaN   31.67  26.0         NaN        n  \n",
       "347       18947.0  1415770.0    6.00  29.0     50196.0        n  \n",
       "820           NaN  1678780.0   41.00  22.0         NaN        n  \n",
       "\n",
       "[1669 rows x 18 columns]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45a8b16",
   "metadata": {},
   "source": [
    "## Reconstructing Data\n",
    "\n",
    "Explain what each line in the following short program does:\n",
    "what is in `df1`, `df2`, etc.?\n",
    "\n",
    "~~~python\n",
    "df1 = pd.read_csv('data/TADPOLE_select.csv', index_col='PTID_Key')\n",
    "df2 = df1[df1['PTGENDER'] == 'Female']\n",
    "df3 = df2.drop(1507)\n",
    "df4 = df3.drop('EXAMDATE', axis = 1)\n",
    "#df4.to_csv('result.csv')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33965ce3-c641-45f1-b10e-b6e7b3fbb4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88937e34",
   "metadata": {},
   "source": [
    "## Selecting Indices\n",
    "\n",
    "Explain in simple terms what `idxmin` and `idxmax` do. When would you use these methods?\n",
    "\n",
    "~~~python\n",
    "data = pd.read_csv('data/TADPOLE_select.csv', index_col='PTID_Key')\n",
    "numeric_columns = data.columns[data.dtypes == 'float64']\n",
    "data = data.loc[:, numeric_columns]\n",
    "data.idxmin()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b759801b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45f674b8",
   "metadata": {},
   "source": [
    "~~~python\n",
    "data.idxmax()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d858993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c104d262",
   "metadata": {},
   "source": [
    "## Practice with Selection\n",
    "\n",
    "Load the GDP data for Europe as `data` \n",
    "```python\n",
    "data = pd.read_csv('data/gapminder_gdp_europe.csv', index_col='country')\n",
    "```\n",
    "Using this DataFrame, write an expression to select each of the following:\n",
    "\n",
    "- GDP per capita for all countries in 1982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ac5379-fa89-45f2-8e62-eb36e7e72c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ea0161c",
   "metadata": {},
   "source": [
    "- GDP per capita for Denmark for all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a93f9a-5a2e-4eeb-84d9-0fb3ceef8da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7cce2bf",
   "metadata": {},
   "source": [
    "- GDP per capita for all countries for years *after* 1985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6936d916-0ba1-4e13-84a0-cf319d77b69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c176b49a-1ea0-42a7-8756-880ebf59ead2",
   "metadata": {},
   "source": [
    "Note that pandas is smart enough to recognize the number at the end of the column label and does not give you an error, although no column named `gdpPercap_1985` actually exists. This is useful if new columns are added to the CSV file later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b319fc0",
   "metadata": {},
   "source": [
    "- GDP per capita for each country in 2007 as a multiple of GDP per capita for that country in 1952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f419464-1b65-43ce-8313-3ebb7901f3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69fdf9ab",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary of Key Points:\n",
    "- pandas DataFrames are a powerful way of storing and working with tabular (row/column) data\n",
    "- pandas columns and rows can have names\n",
    "- pandas row names are called *indexes* which are numeric by default, but can be given other labels\n",
    "- Use the `.iloc[]` method with a DataFrame to select values by integer location, using [row, column] format\n",
    "- Use the `.loc[]` method with a DataFrame to select rows and/or columns, using named slices\n",
    "- Use `:` on its own to mean all columns or all rows\n",
    "- Result of slicing can be used in further operations\n",
    "- Use comparisons to select data based on value\n",
    "- Select values or `NaN` using a Boolean mask\n",
    "- use split-apply-combine to derive analytics from groupings within a DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
